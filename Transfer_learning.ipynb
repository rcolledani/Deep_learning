{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "TP4_transfer_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHec37mZSej5"
      },
      "source": [
        "# Small data and deep learning\n",
        "This Pratical session proposes to study several techniques for improving challenging context, in which few data and resources are available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb6V9ZimSej-"
      },
      "source": [
        "# Introduction\n",
        "Assume we are in a context where few \"gold\" labeled data are available for training, say $\\mathcal{X}_{\\text{train}}\\triangleq\\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$, where $N_{\\text{train}}$ is small. A large test set $\\mathcal{X}_{\\text{test}}$ is available. A large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
        "\n",
        "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question:\n",
        "\n",
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   XXX  | XXX | XXX | XXX |\n",
        "\n",
        "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset)\n",
        "\n",
        "In your final report, please keep the logs of each training procedure you used. We will only run this jupyter if we have some doubts on your implementation. \n",
        "\n",
        "__The total file sizes should be reasonable (feasible with 2MB only!). You will be asked to hand in the notebook, together with any necessary files required to run it if any.__\n",
        "\n",
        "\n",
        "You can use https://colab.research.google.com/ to run your experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxJPCnveSej_"
      },
      "source": [
        "## Training set creation\n",
        "__Question 1 (2 points):__ Propose a dataloader or modify the file located at https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py in order to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uep-k0xASej_"
      },
      "source": [
        "## Download the CIFAR10 dataset using the PyTorch dataloaders\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# *****START CODE \n",
        "## Data\n",
        "##Here you are free to add further transform functions if you wish\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "transform_train_transfer = transforms.Compose([transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "transform_test_transfer = transforms.Compose([transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainset_transfer = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_transfer)\n",
        "\n",
        "\n",
        "L_train = []\n",
        "L_train_transfer =[]\n",
        "for i in range(100):\n",
        "    L_train.append(trainset[i])\n",
        "    L_train_transfer.append(trainset_transfer[i])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(L_train, batch_size= 10 , shuffle=True)\n",
        "trainloader_transfer = torch.utils.data.DataLoader(L_train_transfer, batch_size= 10 , shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testset_transfer = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test_transfer)\n",
        "\n",
        "L_test = []\n",
        "L_test_transfer =[]\n",
        "for i in range(len(testset)):\n",
        "    L_test.append(testset[i])\n",
        "    L_test_transfer.append(testset_transfer[i])\n",
        "    \n",
        "testloader = torch.utils.data.DataLoader(L_test, batch_size= 10, shuffle=False)\n",
        "testloader_transfer = torch.utils.data.DataLoader(L_test_transfer, batch_size= 10, shuffle=False)\n",
        "\n",
        "\n",
        "L_weak = []\n",
        "for i in range(100, 3000):\n",
        "    L_weak.append(trainset_transfer[i])\n",
        "    \n",
        "weakloader = torch.utils.data.DataLoader(L_weak, batch_size= 100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXuCxPUISekA"
      },
      "source": [
        "trainset[1][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCEA8W-2SekB"
      },
      "source": [
        "This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project. The remaining samples correspond to $\\mathcal{X}$. The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQbUdzpNSekB"
      },
      "source": [
        "## Testing procedure\n",
        "__Question 2 (1.5 points):__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6wYvtZUSekC"
      },
      "source": [
        "Because we do not have a lot of data, the training procedure is difficult. However, several solutions are possible to manage this problem. One way is to use data augmentation, that is adding various transformations to real data, like rotations, flips, contrasts, color balance, noise to our image. \n",
        "On the other hand, we can rely on multi-tasking. Especially if we have related enought tasks, we could increase in accuracy for the real targeted task. \n",
        "Finally, a last solution could be to add some noise in our data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmohDeizSekC"
      },
      "source": [
        "# Raw approach: the baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BdlZlOSekC"
      },
      "source": [
        "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performance with reported numbers from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
        "\n",
        "The key ingredients for training a CNN are the batch size, as well as the learning rate schedule, i.e. how to decrease the learning rate as a function of the number of epochs. A possible schedule is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the laerning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
        "\n",
        "You can get some baselines accuracies in this paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf. Obviously, it is a different context for those researchers who had access to GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30skqZSgSekD"
      },
      "source": [
        "## ResNet architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7ORYk67SekD"
      },
      "source": [
        "__Question 3 (4 points):__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1512.03385). Please report the accuracy obtained on the whole dataset as well as the reference paper/GitHub link.\n",
        "\n",
        "*Hint:* You can re-use the following code: https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40% accuracy on $\\mathcal{X}_{\\text{train}}$ (\\~2 minutes) and 20% accuracy on $\\mathcal{X}_{\\text{test}}$ (\\~5 minutes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_XwmbmkBuon"
      },
      "source": [
        "All the functions below come from the github link provided above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNzoHOjoSekE"
      },
      "source": [
        "import os\n",
        "import argparse\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsel__RZSekF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb3ES73FSekF"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "term_width = 80\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCXL-ne2SekG"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "    \n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhqUnEuASekG"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "args = parser.parse_args()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzmcBfAqSekH"
      },
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "model = ResNet18()\n",
        "\n",
        "model = model.to(device)\n",
        "if device == 'cuda':\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU0oPtfbSekH"
      },
      "source": [
        "# Training\n",
        "def train(epoch, data):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    compt = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(data):\n",
        "\n",
        "        \n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        targets = targets.long()\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += [loss.item()]\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print(\"Iteration: {0} | Loss: {1} | Training accuracy: {2}%\".format(epoch+1, np.mean(train_loss), 100. *correct/total))\n",
        "    return (\"Iteration: {0} | Loss: {1} | Training accuracy: {2}%\".format(epoch+1, train_loss, 100. *correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqUI6X8KSekI"
      },
      "source": [
        "def test(epoch, data):\n",
        "    best_acc = 0\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(data):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += [loss.item()]\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "    print(\"Iteration: {0} | Loss: {1} | Test accuracy: {2}%\".format(epoch+1, np.mean(test_loss), 100. *correct/total))\n",
        "    return (\"Iteration: {0} | Loss: {1} | Test accuracy: {2}%\".format(epoch+1, np.mean(test_loss), 100. *correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tZfAo330SekI"
      },
      "source": [
        "for epoch in range(10):  # You should get about 53% accuracy on train and 21% on test\n",
        "    train(epoch,trainloader)\n",
        "    test(epoch,testloader)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieyIDy-h1xp3"
      },
      "source": [
        "for batch_idx, (inputs, targets) in enumerate(trainloader):\r\n",
        "  inputs, targets = inputs.to(device), targets.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGeGVmkcSekI"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "d1 = {'Model': ['Resnet18()'], 'Number of epochs': [10], 'Train accuracy': ['53%'], 'Test accuracy': ['21%']}\n",
        "df1 = pd.DataFrame(data = d1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6146gqmHSekI"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2XGCpj8SekJ"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvq_sLBNSekJ"
      },
      "source": [
        "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlPNzJmoSekJ"
      },
      "source": [
        "## ImageNet features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qtjzrE9SekJ"
      },
      "source": [
        "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on: https://pytorch.org/docs/stable/torchvision/models.html.\n",
        "\n",
        "__Question 4 (3 points):__ Pick a model from the list above, adapt it for CIFAR and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5BoUqMhDGjv"
      },
      "source": [
        "For this given part, we chose the AlexNet model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPE8Nx0ySekJ"
      },
      "source": [
        "import torchvision.models as models\r\n",
        "import torch.nn  as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymCZs3WBSekJ"
      },
      "source": [
        "# Model - Newmodel = alexnet\n",
        "print('==> Building model..')\n",
        "\n",
        "model = models.alexnet(pretrained = True)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "if device == 'cuda':\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.module.classifier.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnkLVoc-SekK"
      },
      "source": [
        "for epoch in range(10):  #You should get about 97% for training and 32% accuracy for testing\n",
        "    train(epoch,trainloader_transfer)\n",
        "    test(epoch, testloader_transfer)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikOuxJRJ1V8G"
      },
      "source": [
        "d2 = {'Model': ['AlexNet'], 'Number of epochs': [10], 'Train accuracy': ['97%'], 'Test accuracy': ['31.8%']}\r\n",
        "df2 = pd.DataFrame(data = d2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPDf9NNg1iMa"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIw9LSUSekK"
      },
      "source": [
        "# Incorporating *a priori*\n",
        "Geometrical *a priori* are appealing for image classification tasks. For now, we only consider linear transformations $\\mathcal{T}$ of the inputs $x:\\mathbb{S}^2\\rightarrow\\mathbb{R}$ where $\\mathbb{S}$ is the support of an image, meaning that:\n",
        "\n",
        "$$\\forall u\\in\\mathbb{S}^2,\\mathcal{T}(\\lambda x+\\mu y)(u)=\\lambda \\mathcal{T}(x)(u)+\\mu \\mathcal{T}(y)(u)\\,.$$\n",
        "\n",
        "For instance if an image had an infinite support, a translation $\\mathcal{T}_a$ by $a$ would lead to:\n",
        "\n",
        "$$\\forall u, \\mathcal{T}_a(x)(u)=x(u-a)\\,.$$\n",
        "\n",
        "Otherwise, one has to handle several boundary effects.\n",
        "\n",
        "__Question 5 (1.5 points):__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4eWhzg-SekL"
      },
      "source": [
        "# Rotation \n",
        "An issue which may raise with this technic is that image dimension may not be preserved after rotation. (ex: if an image is a triangle, rotating it by 180 degrees would preserve the size)\n",
        "\n",
        "# Scaling effects\n",
        "An issue with scaling effects is that the image can be scaled outward or inward and consequently could be larger than the original image size or reduce the image size (forcing to make assumptions about what lies beyond the boundary).\n",
        "\n",
        "\n",
        "# Translations\n",
        "One of the main cons of translations is that the targeted information could be loss if the translation is too significative. We could tackle this problem by tuning a translation threshold that will prevent the translation to be too big.\n",
        "But in an overall aspect, it force our convolutional network to look at everywhere.\n",
        "\n",
        "\n",
        "# Ideas to tackle the lack of background after the transformation\n",
        "There are many methods to tackle this issue in the documentation. Here are some of them :\n",
        "  -  **Constant** :\n",
        "The idea is to fill the unknown region with some constant value. This may not work for natural images, but can work for images taken in a monochromatic background\n",
        "\n",
        "  - **Edge** :\n",
        "The edge values of the image are extended after the boundary. This method can work for mild translations.\n",
        "\n",
        "  - **Reflect** :\n",
        "The image pixel values are reflected along the image boundary. This method is useful for continuous or natural backgrounds containing trees, mountains etc.\n",
        "\n",
        "  - **Wrap** : \n",
        "We repeat the image beyond its boundary. This method is not as popularly used as the rest as it does not make sense for a lot of scenarios.\n",
        "\n",
        "\n",
        "# Color changes\n",
        "The results look more artistic than realistic and the computational cost is quiet high, but results are very good.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdm17S3YSekL"
      },
      "source": [
        "## Data augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmuV7Dn-SekL"
      },
      "source": [
        "__Question 6 (3 points):__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ with them and report the accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ3p2D12D3fw"
      },
      "source": [
        "In this part, we tried different data augmentation methods and report for some combinations of them the accuracy obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnf4cTtXSekL"
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5viwTGSekL"
      },
      "source": [
        "class ImgAugTransform:\n",
        "    def __init__(self):\n",
        "        self.aug = iaa.Sequential([\n",
        "            iaa.Scale((320, 96)),\n",
        "            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
        "            iaa.Fliplr(0.5),\n",
        "            iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
        "            iaa.Sometimes(0.25,\n",
        "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
        "                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
        "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
        "        ])\n",
        "      \n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        return self.aug.augment_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIHOcRkCSekL"
      },
      "source": [
        "##Here you are free to add further transform functions if you wish\n",
        "import PIL\n",
        "\n",
        "print('==> Preparing data..')\n",
        "transform_trainbis = torchvision.transforms.Compose([\n",
        "  #  torchvision.transforms.Resize((320,96)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "#    transforms.ColorJitter(\n",
        " #           brightness=0.1*torch.abs(torch.randn(1)).item(),\n",
        " #           contrast=0.1*torch.abs(torch.randn(1)).item(),\n",
        "  #          saturation=0.1*torch.abs(torch.randn(1)).item(),\n",
        "  #          hue=0.1*torch.abs(torch.randn(1)).item()),\n",
        "    torchvision.transforms.RandomCrop(32, padding = 4),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    #torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
        "    #torchvision.transforms.RandomRotation(40, resample=PIL.Image.NEAREST),\n",
        "    torchvision.transforms.Normalize((0.1307,),(0.3081,))\n",
        "    \n",
        "])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.45,), (0.45,))])\n",
        "\n",
        "transform_testbis = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "trainset_bis = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "L_trainbis = []\n",
        "for i in range(100):\n",
        "    L_trainbis.append(trainset_bis[i])\n",
        "\n",
        "\n",
        "trainloaderbis = torch.utils.data.DataLoader(L_trainbis, batch_size= 5, shuffle=True)\n",
        "\n",
        "testset_bis = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_testbis)\n",
        "\n",
        "L_testbis = []\n",
        "for i in range(len(testset_bis)):\n",
        "    L_testbis.append(testset_bis[i])\n",
        "    \n",
        "testloaderbis = torch.utils.data.DataLoader(L_testbis, batch_size= 5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9OJMllDSekM"
      },
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "model = ResNet18()\n",
        "\n",
        "model = model.to(device)\n",
        "if device == 'cuda':\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay= 5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rEj6mKA3SekM"
      },
      "source": [
        "import random\n",
        "#random.shuffle(dataset)\n",
        "for epoch in range(20):\n",
        "    train(epoch,trainloaderbis)\n",
        "    test(epoch, testloaderbis)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkgzbq-xSekM"
      },
      "source": [
        " # Here we are reported all our results in a dataframe.\n",
        "\n",
        " pd.set_option('max_colwidth', 400)\n",
        "\n",
        "\n",
        "d2 = {'Model': ['Resnet18() + RandomHorizontalFlip(p=0.5) + RandomVerticalFlip(p=0.5) + RandomRotation(45, resample=PIL.Image.NEAREST) + Normalize((0.1307,),(0.3081,))',\n",
        "               'Resnet18() + ColorJitter + RandomHorizontalFlip(p=0.5) + RandomVerticalFlip(p=0.5) + RandomRotation(45, resample=PIL.Image.NEAREST) + Normalize((0.1307,),(0.3081,))',\n",
        "               'Resnet18() + RandomCrop(32, padding = 4) + RandomHorizontalFlip(p=0.5) + Normalize((0.1307,),(0.3081,) ',\n",
        "                'Resnet18() + RandomCrop(32, padding = 4) + RandomHorizontalFlip(p=0.5) + Normalize((0.1307,),(0.3081,)',\n",
        "                'Resnet18() + Resize((64,64)) + Colorjitter + RandomCrop(32, padding = 4) + RandomHorizontalFlip(p=0.5) + RandomVerticalFlip(p=0.5) + RandomRotation(45, resample=PIL.Image.NEAREST) + Normalize((0.1307,),(0.3081,))\t'\n",
        "                ,'Resnet18() + Brightness =0.5 + Normalize((0.1307,),(0.3081,))',\n",
        "                'Resnet18() + Brightness =0.8 + Saturation = 0.8 + Normalize((0.1307,),(0.3081,))'],\n",
        "      'Parameters' : ['batch_size = 10 + SGD + lr = 0.01',\n",
        "                     'batch_size = 5 + Adam + lr = 0.01',\n",
        "                     'batch_size = 5 + SGD + lr = 0.01',\n",
        "                     'batch_size = 5 + SGD + lr = 0.01',\n",
        "                      'batch_size = 10 + SGD + lr = 0.01\t',\n",
        "                      'batch_size = 10 + Adam + lr = 0.0001',\n",
        "                      'batch_size = 10 + Adam + lr = 0.0001'], \n",
        "      'Number of epochs': [15, 20, 20, 30,30,30,30],\n",
        "      'Train accuracy': ['89%','41%','91%', '96%','96%','100%','100%'],\n",
        "      'Test accuracy': ['19.66%','18.27%', '23.07%', '22.61%',\t'20.85%','23.62%',\"20.82%\"]}\n",
        "\n",
        "\n",
        "df2 = pd.DataFrame(data = d2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD8uLT3TSekM"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFOpGFjySekN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image (that helps us better know which data augmentation used or not used)\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloaderbis)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR9y57mmSekN"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7r7un9SekN"
      },
      "source": [
        "__Question 7 (5 points):__ Write a short report explaining the pros and the cons of each methods that you implemented. 25% of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results.\r\n",
        "\r\n",
        "\r\n",
        "During this Lab, We've dealed with 3 differents methode to train a model with a small dataset : **Training on a Resnet**, **Transfer learning** and **Data augmentation**. Lets now compare theme and see their advantages.\r\n",
        "\r\n",
        "- **Transfer Learning**  : \r\n",
        "This method consist in using a model already train on an other dataset, on a quite similar task. We are just modifying the last fully-connected layer that apply the classification task, and train only the final layer on the train set. It is a very convenient method that allow us to reach a good accuracy on the test set with a reduced computational time. \r\n",
        "\r\n",
        "  However, It has some disadvantages that need to be taken into account. The first thing to take care is that the model has been trained on the same kind of data (type of image, size..) and with a very large dataset.\r\n",
        "\r\n",
        "- **Data augmentation**  : Here we \"artificially\" augment the size of our dataset by applying some transformation on images. This allow us to get new images and have a bigger dataset. \r\n",
        "\r\n",
        "  This method is very useful when we have a small dataset, but if it's not carefully use, it can quickly lead to a non realistic dataset. In fact, some transformation can lead to a non sense image that doesn't exist in the real life (e.g. : an image of elephent reversed). So each transformation applied on the dataset need to be chosen carefully, so that the model can train on images closed to the original dataset.\r\n",
        "\r\n",
        "- **Resnet** : The network here simply don't have enough images to catch the pattern of each class in the dataset\r\n",
        "\r\n",
        "To sum up our experimentation on the lab, we figure out that the method method that reach the best accuracy is the transferd learning (32%) followed by the data augmentation (23%) and finally the supervised method (21%).\r\n",
        "One can think that it would be good to combine the 2 first method in order to get a better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAa8ATdX5rRG"
      },
      "source": [
        "# Here we plot the results we got based on the three methods used\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "list_methode = ['Resnet18' , 'Alexnet(pre-trained)', 'data augmentation']\r\n",
        "list_acc_train = [53,97,100]\r\n",
        "list_acc_test = [21,32,23.62]\r\n",
        "\r\n",
        "plt.plot(list_methode,list_acc_train, label='Train accuracy')\r\n",
        "plt.plot(list_methode,list_acc_test, label='Test accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OrWJpskSekN"
      },
      "source": [
        "# Weak supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Jo1q0uSekN"
      },
      "source": [
        "__Bonus \\[open\\] question (up to 3 points):__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edrg84u6FEJ0"
      },
      "source": [
        "On this part, we tried on a weakly supervised method that aims to train our model on a small dataset labelled (100 datas). Then our model make prediction on the remaining training dataset and suppose that its prediction are true. \r\n",
        "We then train our model and the whole training set and make prediction on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3kV_iIKWz9B"
      },
      "source": [
        "# Model - Newmodel = alexnet\r\n",
        "print('==> Building model..')\r\n",
        "\r\n",
        "model = models.alexnet(pretrained = True)\r\n",
        "\r\n",
        "\r\n",
        "for param in model.parameters():\r\n",
        "    param.requires_grad = False\r\n",
        "    \r\n",
        "\r\n",
        "num_ftrs = model.classifier[6].in_features\r\n",
        "model.classifier[6] = nn.Linear(num_ftrs, 10)\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "\r\n",
        "if device == 'cuda':\r\n",
        "    model = torch.nn.DataParallel(model)\r\n",
        "    cudnn.benchmark = True\r\n",
        "\r\n",
        "if args.resume:\r\n",
        "    # Load checkpoint.\r\n",
        "    print('==> Resuming from checkpoint..')\r\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\r\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\r\n",
        "    model.load_state_dict(checkpoint['net'])\r\n",
        "    best_acc = checkpoint['acc']\r\n",
        "    start_epoch = checkpoint['epoch']\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model.module.classifier.parameters(), lr=args.lr,\r\n",
        "                      momentum=0.9, weight_decay=5e-4)\r\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\r\n",
        "\r\n",
        "for epoch in range(10):  # You should get about 97% for training and 32% accuracy for testing\r\n",
        "    train(epoch,trainloader_transfer)\r\n",
        "    test(epoch,testloader_transfer)\r\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9psFNDsYSekO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LG2zmu2X8AR"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "model.eval()\r\n",
        "big_train=[]\r\n",
        "with torch.no_grad():\r\n",
        "    for batch_idx, (inputs, targets) in enumerate(weakloader):\r\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\r\n",
        "        outputs = model(inputs)\r\n",
        "        _, predicted = outputs.max(1)\r\n",
        "        big_train.append((inputs,predicted))\r\n",
        "\r\n",
        "input =[]\r\n",
        "target=[]\r\n",
        "for i in range (len(big_train)):\r\n",
        "  inputs,targets = big_train[i]\r\n",
        "  inputs = inputs.cpu()\r\n",
        "  targets = targets.cpu()\r\n",
        "  input.append(inputs.numpy())\r\n",
        "  target.append(targets.numpy())\r\n",
        "\r\n",
        "transform_bigdataset = transforms.Compose([transforms.Resize((32,32)),\r\n",
        "    transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\r\n",
        "\r\n",
        "input = torch.Tensor(input).reshape((2900,3,64,64)) # transform to torch tensor\r\n",
        "target = torch.Tensor(target).reshape((2900))\r\n",
        "\r\n",
        "input = F.interpolate(input, (32, 32))\r\n",
        "\r\n",
        "\r\n",
        "big_dataset = TensorDataset(torch.squeeze(input),torch.squeeze(target)) # We create our new and bigger datset\r\n",
        "big_dataloader = DataLoader(big_dataset, batch_size=10, shuffle=True ) # We create our new dataloader\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzo67YQhqmj0"
      },
      "source": [
        "for batch_idx, (inputs, targets) in enumerate(big_dataloader):\r\n",
        "  inputs, targets = inputs.to(device), targets.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn79bpMpaqvJ"
      },
      "source": [
        "model = ResNet18()\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "if device == 'cuda':\r\n",
        "    model = torch.nn.DataParallel(model)\r\n",
        "    cudnn.benchmark = True\r\n",
        "\r\n",
        "if args.resume:\r\n",
        "    # Load checkpoint.\r\n",
        "    print('==> Resuming from checkpoint..')\r\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\r\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\r\n",
        "    model.load_state_dict(checkpoint['net'])\r\n",
        "    best_acc = checkpoint['acc']\r\n",
        "    start_epoch = checkpoint['epoch']\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr,\r\n",
        "                      momentum=0.9, weight_decay=5e-4)\r\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\r\n",
        "model.train()\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(20):  # You should get about 90% for training and 26% accuracy for testing\r\n",
        "    train(epoch,big_dataloader)\r\n",
        "    test(epoch, testloader)\r\n",
        "    scheduler.step()\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}